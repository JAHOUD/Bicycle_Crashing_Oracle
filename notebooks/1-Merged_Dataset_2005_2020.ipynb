{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f2364ee-7121-4321-b31b-2dfc5ad41def",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook is used to analyse, concat and merge all data from 2005 to 2020, and generate a 'raw' csv files with all the available data.  \n",
    "This 'raw' CSV file will then be useful for our preprocessing (removing unused columns or rows, keeping the rows we need...).\n",
    "\n",
    "***\n",
    "# Import libraries & packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c0138c73-865e-4309-a07e-dd6b1fe387de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c26da05",
   "metadata": {},
   "source": [
    "***\n",
    "# Loading files from 2018 and 2019, for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6a39ee1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WonderSSJ9\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "carac_2018 = pd.read_csv('data/2018/caracteristiques-2018.csv', sep=',', encoding = \"ANSI\")\n",
    "vehic_2018 = pd.read_csv('data/2018/vehicules-2018.csv',sep=',', encoding = \"ANSI\")\n",
    "lieux_2018 = pd.read_csv('data/2018/lieux-2018.csv', sep=',', encoding = \"ANSI\")\n",
    "usage_2018 = pd.read_csv('data/2018/usagers-2018.csv', sep=',', encoding = \"ANSI\")\n",
    "\n",
    "carac_2019 = pd.read_csv('data/2019/caracteristiques-2019.csv', sep=';')\n",
    "vehic_2019 = pd.read_csv('data/2019/vehicules-2019.csv', sep=';')\n",
    "lieux_2019 = pd.read_csv('data/2019/lieux-2019.csv', sep=';')\n",
    "usage_2019 = pd.read_csv('data/2019/usagers-2019.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c336c21",
   "metadata": {},
   "source": [
    "***\n",
    "# Analysing columns before/after 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ff808dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carac 2018 columns     :  ['Num_Acc', 'an', 'mois', 'jour', 'hrmn', 'lum', 'agg', 'int', 'atm', 'col', 'com', 'adr', 'gps', 'lat', 'long', 'dep']\n",
      "Carac 2019 columns     :  ['Num_Acc', 'jour', 'mois', 'an', 'hrmn', 'lum', 'dep', 'com', 'agg', 'int', 'atm', 'col', 'adr', 'lat', 'long']\n",
      "\n",
      "\n",
      "vehic 2018 columns     :  ['Num_Acc', 'senc', 'catv', 'occutc', 'obs', 'obsm', 'choc', 'manv', 'num_veh']\n",
      "vehic 2019 columns     :  ['Num_Acc', 'id_vehicule', 'num_veh', 'senc', 'catv', 'obs', 'obsm', 'choc', 'manv', 'motor', 'occutc']\n",
      "\n",
      "\n",
      "lieux 2018 columns     :  ['Num_Acc', 'catr', 'voie', 'v1', 'v2', 'circ', 'nbv', 'pr', 'pr1', 'vosp', 'prof', 'plan', 'lartpc', 'larrout', 'surf', 'infra', 'situ', 'env1']\n",
      "lieux 2019 columns     :  ['Num_Acc', 'catr', 'voie', 'v1', 'v2', 'circ', 'nbv', 'vosp', 'prof', 'pr', 'pr1', 'plan', 'lartpc', 'larrout', 'surf', 'infra', 'situ', 'vma']\n",
      "\n",
      "\n",
      "usage 2018 columns     :  ['Num_Acc', 'place', 'catu', 'grav', 'sexe', 'trajet', 'secu', 'locp', 'actp', 'etatp', 'an_nais', 'num_veh']\n",
      "usage 2019 columns     :  ['Num_Acc', 'id_vehicule', 'num_veh', 'place', 'catu', 'grav', 'sexe', 'an_nais', 'trajet', 'secu1', 'secu2', 'secu3', 'locp', 'actp', 'etatp']\n"
     ]
    }
   ],
   "source": [
    "print(\"Carac 2018 columns     : \", list(carac_2018.columns))\n",
    "print(\"Carac 2019 columns     : \", list(carac_2019.columns))\n",
    "print('\\n')\n",
    "print(\"vehic 2018 columns     : \", list(vehic_2018.columns))\n",
    "print(\"vehic 2019 columns     : \", list(vehic_2019.columns))\n",
    "print('\\n')\n",
    "print(\"lieux 2018 columns     : \", list(lieux_2018.columns))\n",
    "print(\"lieux 2019 columns     : \", list(lieux_2019.columns))\n",
    "print('\\n')\n",
    "print(\"usage 2018 columns     : \", list(usage_2018.columns))\n",
    "print(\"usage 2019 columns     : \", list(usage_2019.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe45a98-efbf-4744-8897-20d1fe7819c5",
   "metadata": {},
   "source": [
    "***\n",
    "# Concat old CSV file : 2005 - 2018\n",
    "\n",
    "Remarks:\n",
    "- Files before 2019 (2005-2018) are separated with commas ','\n",
    "- Files before 2019 (2005-2018) are encoded in ANSI\n",
    "- File 'caracteristiques' in 2009 is separated with tabulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d8efbdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We initialyze our 4 dataframes\n",
    "concat_carac_old = pd.DataFrame()\n",
    "concat_vehic_old = pd.DataFrame()\n",
    "concat_lieux_old = pd.DataFrame()\n",
    "concat_usage_old = pd.DataFrame()\n",
    "\n",
    "# We old separators and encoding (before 2019)\n",
    "separator = ','\n",
    "encoding = 'ANSI'\n",
    "\n",
    "# Loading and concatenation of files for each year (the four files are not merged yet)\n",
    "for year in range(2005, 2019):\n",
    "\n",
    "    # Only one file is different from the others in 2009 : carac (separator is a tabulation and encoding is changed)\n",
    "    if year == 2009:\n",
    "        concat_carac_old = pd.concat([concat_carac_old, pd.read_csv(f'data/{year}/caracteristiques-{year}.csv', sep='\\t', encoding = 'UTF-8')])\n",
    "    # Otherwise it's the same as the 3 other files below\n",
    "    else:\n",
    "        concat_carac_old = pd.concat([concat_carac_old, pd.read_csv(f'data/{year}/caracteristiques-{year}.csv', sep=separator, encoding = encoding)])\n",
    "\n",
    "    concat_vehic_old = pd.concat([concat_vehic_old, pd.read_csv(f'data/{year}/vehicules-{year}.csv', sep=separator, encoding = encoding)])\n",
    "    concat_lieux_old = pd.concat([concat_lieux_old, pd.read_csv(f'data/{year}/lieux-{year}.csv', sep=separator, encoding = encoding)])\n",
    "    concat_usage_old = pd.concat([concat_usage_old, pd.read_csv(f'data/{year}/usagers-{year}.csv', sep=separator, encoding = encoding)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dab6e009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat_carac_old: 958469 lines\n",
      "concat_vehic_old: 1635811 lines\n",
      "concat_lieux_old: 958469 lines\n",
      "concat_usage_old: 2142195 lines\n"
     ]
    }
   ],
   "source": [
    "# Displaying some infos on our contenated files\n",
    "print('concat_carac_old:', concat_carac_old.shape[0], 'lines')\n",
    "print('concat_vehic_old:', concat_vehic_old.shape[0], 'lines')\n",
    "print('concat_lieux_old:', concat_lieux_old.shape[0], 'lines')\n",
    "print('concat_usage_old:', concat_usage_old.shape[0], 'lines')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45785425",
   "metadata": {},
   "source": [
    "***\n",
    "# Apply transformation rules to the old files to obtain 'raw' dataframes before the concat with newer files\n",
    "\n",
    "**caracteristiques** :\n",
    "- Remove column 'gps'\n",
    "- 'an' : add '20' before the date (we only have '18') - we can add 2000 to the int value\n",
    "- 'hrmn' : split to get 'HH:mm' format. Be careful with zeros (40 -> 00:40)\n",
    "- 'atm', 'col' : replace NaN with '-1' and change to int\n",
    "- 'dep' : remove the last digit *if it is equal to 0*, change it to string\n",
    "- 'com' : the code is just the last digits, add the department (and zeros) to get the complete city (5 and 590 -> 59005), change it to string\n",
    "- 'lat' and 'long' : divide the float by 100 000 (5055737 -> 50.55737)\n",
    "\n",
    "**vehicules**:\n",
    "- We don't have the id of the vehicle : no need, we will remove it on the new files\n",
    "- 'motor' is missing: create the column with '-1\n",
    "- 'senc', 'obs', 'obsm', 'choc', 'manv' : replace NaN with '-1' and change to int\n",
    "\n",
    "**lieux** :\n",
    "- Compare 'env1' (old file) with 'vma' in the new files\n",
    "  - Nothing in common, remove both columns (env1 in old files, vma in newer files)\n",
    "- 'circ', 'nbv', 'pr', 'pr1', 'vosp', 'prof', 'plan', 'surf', 'infra', 'situ', 'catr' : replace NaN with '-1' and change to int\n",
    "\n",
    "**usagers** :\n",
    "- We don't have the id of the vehicle : no need, we will remove it on the new files\n",
    "- 'secu' has become 'secu1', 'secu2' and 'secu3'\n",
    "  - The values are partially consistent, use the function made by Houssam to align on 2019\n",
    "  - Rename secu to secu1\n",
    "  - On newer files, we will keep only secu1, and remove secu2 and secu3 (almost empty anyway)\n",
    "- 'place', 'trajet', 'locp', 'actp', 'etatp', 'an_nais': replace NaN with '-1' and change to int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4da8957",
   "metadata": {},
   "source": [
    "### caracteristiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7fa1613f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove column 'gps'\n",
    "concat_carac_old = concat_carac_old.drop('gps', axis = 1)\n",
    "\n",
    "# 'an' : add '20' before the date (we only have '18') - we can add 2000 to the int value\n",
    "concat_carac_old.an += 2000\n",
    "\n",
    "# 'hrmn' : split to get 'HH:mm' format. Be careful with zeros (40 -> 00:40)\n",
    "concat_carac_old.hrmn = concat_carac_old.hrmn.astype(str)\n",
    "concat_carac_old.hrmn = concat_carac_old.hrmn.apply(lambda x : ('0000'+x)[-4:])\n",
    "concat_carac_old.hrmn = concat_carac_old.hrmn.apply(lambda x : x[:2] + ':' + x[2:])\n",
    "\n",
    "# 'atm', 'col' : replace NaN with '-1' and change to int\n",
    "concat_carac_old.fillna({x:-1 for x in ['atm','col']}, inplace= True)\n",
    "concat_carac_old[['atm', 'col']] = concat_carac_old[['atm', 'col']].astype(int)\n",
    "\n",
    "# 'dep' : remove the last digit *if it is equal to 0*, change it to string\n",
    "concat_carac_old.loc[concat_carac_old.dep % 10 == 0, 'dep'] = concat_carac_old.loc[concat_carac_old.dep % 10 == 0, 'dep'] / 10\n",
    "concat_carac_old.dep = concat_carac_old.dep.astype(int)\n",
    "concat_carac_old.dep = concat_carac_old.dep.astype(str)\n",
    "\n",
    "# 'com' : the code is just the last digits, add the department (and zeros) to get the complete city (5 and 590 -> 59005), change it to string\n",
    "concat_carac_old.fillna({'com':'0'}, inplace= True)\n",
    "concat_carac_old.com = concat_carac_old.com.astype(int)\n",
    "concat_carac_old.com = concat_carac_old.com.astype(str)\n",
    "# We make sure all communes are encoded with 3 digits (starts with 0 if necessary)\n",
    "concat_carac_old.com = concat_carac_old.com.apply(lambda x : ('000'+x)[-3:])\n",
    "# We concat the dep (only first 2 digits) + com\n",
    "concat_carac_old.com = concat_carac_old.dep.str[:2] + concat_carac_old.com\n",
    "# We make sure all communes are now encoded with 5 digits (starts with 0 if necessary)\n",
    "concat_carac_old.com = concat_carac_old.com.apply(lambda x : ('0'+x)[-5:])\n",
    "\n",
    "# 'lat' and 'long' : divide the float by 100 000 (5055737 -> 50.55737)\n",
    "concat_carac_old.lat = concat_carac_old.lat.astype(float)\n",
    "concat_carac_old.lat = concat_carac_old.lat / 100000\n",
    "concat_carac_old.long = concat_carac_old.long.replace({'-':'0'}) # Some long values are '-' instead of NaN\n",
    "concat_carac_old.long = concat_carac_old.long.astype(float)\n",
    "concat_carac_old.long = concat_carac_old.long / 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4da8957",
   "metadata": {},
   "source": [
    "### vehicules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "143a4564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'motor' is missing: create the column with '-1\n",
    "concat_vehic_old['motor'] = -1\n",
    "\n",
    "# 'senc', 'obs', 'obsm', 'choc', 'manv' : replace NaN with '-1' and change to int\n",
    "concat_vehic_old.fillna({x:-1 for x in ['senc', 'obs', 'obsm', 'choc', 'manv']}, inplace= True)\n",
    "concat_vehic_old[['senc', 'obs', 'obsm', 'choc', 'manv']] = concat_vehic_old[['senc', 'obs', 'obsm', 'choc', 'manv']].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4da8957",
   "metadata": {},
   "source": [
    "### lieux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "143a4564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove env1 column\n",
    "concat_lieux_old.drop('env1', axis = 1, inplace= True)\n",
    "\n",
    "# 'circ', 'nbv', 'pr', 'pr1', 'vosp', 'prof', 'plan', 'surf', 'infra', 'situ' : replace NaN with '-1' and change to int\n",
    "concat_lieux_old.fillna({x:-1 for x in ['catr','circ', 'nbv', 'pr', 'pr1', 'vosp', 'prof', 'plan', 'surf', 'infra', 'situ']}, inplace= True)\n",
    "concat_lieux_old[['catr','circ', 'nbv', 'pr', 'pr1', 'vosp', 'prof', 'plan', 'surf', 'infra', 'situ']] = concat_lieux_old[['catr','circ', 'nbv', 'pr', 'pr1', 'vosp', 'prof', 'plan', 'surf', 'infra', 'situ']].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4da8957",
   "metadata": {},
   "source": [
    "### usagers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "143a4564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the secu adjusting function, based on the documentation\n",
    "# Old values are encoded on 2 digits\n",
    "def adjust_secu_with_2019(x):\n",
    "    # Values not conform to the doc are changed to '-1'\n",
    "    if len(str(x))!=2 or str(x)[1]=='3' or x==-1 :\n",
    "        y=-1\n",
    "    # If the second digit equals '2' are changed to '0' (equipment not worn)\n",
    "    elif str(x)[1]=='2':\n",
    "        y=0\n",
    "    # Else, the first digit is used\n",
    "    else:\n",
    "        y= int(str(x)[0])\n",
    "    return y\n",
    "\n",
    "# The secu values are partially consistent, use the function made by Houssam to align on 2019\n",
    "\n",
    "concat_usage_old['secu'] = concat_usage_old['secu'].fillna(-1)\n",
    "concat_usage_old['secu'] = concat_usage_old['secu'].astype(int)\n",
    "concat_usage_old.secu = concat_usage_old.secu.apply(adjust_secu_with_2019)\n",
    "\n",
    "\n",
    "# Rename secu to secu1\n",
    "concat_usage_old.rename({'secu':'secu1'}, axis = 'columns', inplace= True)\n",
    "\n",
    "# 'place', 'trajet', 'locp', 'actp', 'etatp', 'an_nais': replace NaN with '-1' and change to int\n",
    "concat_usage_old.fillna({x:-1 for x in ['place', 'trajet', 'locp', 'actp', 'etatp', 'an_nais']}, inplace= True)\n",
    "concat_usage_old[['place', 'trajet', 'locp', 'actp', 'etatp', 'an_nais']] = concat_usage_old[['place', 'trajet', 'locp', 'actp', 'etatp', 'an_nais']].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe45a98-efbf-4744-8897-20d1fe7819c5",
   "metadata": {},
   "source": [
    "***\n",
    "# Concat new CSV file : 2019 - 2020\n",
    "\n",
    "Remarks:\n",
    "- Files in 2019 and 2020 are separated with semicolons ';'\n",
    "- Files before 2019 (2005-2018) are encoded in UTF-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d8efbdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We initialyze our 4 dataframes\n",
    "concat_carac_new = pd.DataFrame()\n",
    "concat_vehic_new = pd.DataFrame()\n",
    "concat_lieux_new = pd.DataFrame()\n",
    "concat_usage_new = pd.DataFrame()\n",
    "\n",
    "# Since separators and encoding change in 2019, we start by using the old ones (before 2019)\n",
    "separator = ';'\n",
    "encoding = 'UTF-8'\n",
    "\n",
    "# Loading and concatenation of files for each year (the four files are not merged yet)\n",
    "for year in range(2019, 2021):\n",
    "    concat_carac_new = pd.concat([concat_carac_new, pd.read_csv(f'data/{year}/caracteristiques-{year}.csv', sep=separator, encoding = encoding)])\n",
    "    concat_vehic_new = pd.concat([concat_vehic_new, pd.read_csv(f'data/{year}/vehicules-{year}.csv', sep=separator, encoding = encoding)])\n",
    "    concat_lieux_new = pd.concat([concat_lieux_new, pd.read_csv(f'data/{year}/lieux-{year}.csv', sep=separator, encoding = encoding)])\n",
    "    concat_usage_new = pd.concat([concat_usage_new, pd.read_csv(f'data/{year}/usagers-{year}.csv', sep=separator, encoding = encoding)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d6de6206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat_carac_new: 106584 lines\n",
      "concat_vehic_new: 181776 lines\n",
      "concat_lieux_new: 106584 lines\n",
      "concat_usage_new: 238272 lines\n"
     ]
    }
   ],
   "source": [
    "# Displaying some infos on our contenated files\n",
    "print('concat_carac_new:', concat_carac_new.shape[0], 'lines')\n",
    "print('concat_vehic_new:', concat_vehic_new.shape[0], 'lines')\n",
    "print('concat_lieux_new:', concat_lieux_new.shape[0], 'lines')\n",
    "print('concat_usage_new:', concat_usage_new.shape[0], 'lines')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d6258e",
   "metadata": {},
   "source": [
    "***\n",
    "# Apply transformation rules to the new files to obtain 'raw' dataframes before the concat with old files\n",
    "\n",
    "**vehicules**:\n",
    "- Remove 'id_vehicule'\n",
    "\n",
    "**lieux** :\n",
    "- Remove column vma\n",
    "- 'pr', 'pr1' : remplace '(1)' by '1' and change to 'int'\n",
    "\n",
    "**usagers** :\n",
    "- Remove 'id_vehicule'\n",
    "- Keep only secu1, and remove secu2 and secu3 (almost empty anyway)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4da8957",
   "metadata": {},
   "source": [
    "### vehicules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "101a2b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'id_vehicule'\n",
    "concat_vehic_new.drop('id_vehicule', axis = 1, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4da8957",
   "metadata": {},
   "source": [
    "### lieux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "101a2b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove column vma\n",
    "concat_lieux_new.drop('vma', axis = 1, inplace= True)\n",
    "\n",
    "# 'pr', 'pr1' : remplace '(1)' by '1' and change to 'int'\n",
    "concat_lieux_new.replace({'(1)':'1'} , inplace=True)\n",
    "concat_lieux_new[['pr', 'pr1']] = concat_lieux_new[['pr', 'pr1']].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4da8957",
   "metadata": {},
   "source": [
    "### usagers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "101a2b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'id_vehicule'\n",
    "concat_usage_new.drop('id_vehicule', axis = 1, inplace= True)\n",
    "\n",
    "# Keep only secu1, and remove secu2 and secu3 (almost empty anyway)\n",
    "concat_usage_new.drop(['secu2', 'secu3'], axis = 1, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe45a98-efbf-4744-8897-20d1fe7819c5",
   "metadata": {},
   "source": [
    "***\n",
    "# Concat old and new files together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3e54b74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_carac = pd.concat([concat_carac_old, concat_carac_new])\n",
    "concat_vehic = pd.concat([concat_vehic_old, concat_vehic_new])\n",
    "concat_lieux = pd.concat([concat_lieux_old, concat_lieux_new])\n",
    "concat_usage = pd.concat([concat_usage_old, concat_usage_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "95fbb9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat_carac: 1065053 lines\n",
      "concat_vehic: 1817587 lines\n",
      "concat_lieux: 1065053 lines\n",
      "concat_usage: 2380467 lines\n"
     ]
    }
   ],
   "source": [
    "# Displaying some infos on our contenated files\n",
    "print('concat_carac:', concat_carac.shape[0], 'lines')\n",
    "print('concat_vehic:', concat_vehic.shape[0], 'lines')\n",
    "print('concat_lieux:', concat_lieux.shape[0], 'lines')\n",
    "print('concat_usage:', concat_usage.shape[0], 'lines')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe45a98-efbf-4744-8897-20d1fe7819c5",
   "metadata": {},
   "source": [
    "***\n",
    "# Merge the 4 CSV files\n",
    "\n",
    "We need to start from 'usagers' and:\n",
    "- Merge with 'caracteristiques' on 'Num_Acc'\n",
    "- Merge with 'lieux' on 'Num_Acc'\n",
    "- Merge with 'vehicules' on 'Num_Acc' and 'num_veh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c791819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be our merged data at the end (all years * 4 files)\n",
    "concat_data = pd.DataFrame()\n",
    "\n",
    "# Merging usagers and caracteristiques on Num_Acc\n",
    "concat_data = pd.merge(concat_usage, concat_carac, on='Num_Acc')\n",
    "\n",
    "# Merging data and lieux on Num_Acc\n",
    "concat_data = pd.merge(concat_data, concat_lieux, on='Num_Acc')\n",
    "\n",
    "# Merging data and vehicules on Num_Acc and num_veh\n",
    "concat_data = pd.merge(concat_data, concat_vehic, on=['Num_Acc', 'num_veh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6fe24710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Num_Acc', 'place', 'catu', 'grav', 'sexe', 'trajet', 'secu1', 'locp',\n",
       "       'actp', 'etatp', 'an_nais', 'num_veh', 'an', 'mois', 'jour', 'hrmn',\n",
       "       'lum', 'agg', 'int', 'atm', 'col', 'com', 'adr', 'lat', 'long', 'dep',\n",
       "       'catr', 'voie', 'v1', 'v2', 'circ', 'nbv', 'pr', 'pr1', 'vosp', 'prof',\n",
       "       'plan', 'lartpc', 'larrout', 'surf', 'infra', 'situ', 'senc', 'catv',\n",
       "       'occutc', 'obs', 'obsm', 'choc', 'manv', 'motor'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the resulting columns\n",
    "concat_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d3e126f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat_data: 2380573 rows\n",
      "concat_data: 50 columns\n"
     ]
    }
   ],
   "source": [
    "# Checking the resulting shape\n",
    "print('concat_data:', concat_data.shape[0], 'rows')\n",
    "print('concat_data:', concat_data.shape[1], 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a8132fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num_Acc</th>\n",
       "      <th>place</th>\n",
       "      <th>catu</th>\n",
       "      <th>grav</th>\n",
       "      <th>sexe</th>\n",
       "      <th>trajet</th>\n",
       "      <th>secu1</th>\n",
       "      <th>locp</th>\n",
       "      <th>actp</th>\n",
       "      <th>etatp</th>\n",
       "      <th>...</th>\n",
       "      <th>infra</th>\n",
       "      <th>situ</th>\n",
       "      <th>senc</th>\n",
       "      <th>catv</th>\n",
       "      <th>occutc</th>\n",
       "      <th>obs</th>\n",
       "      <th>obsm</th>\n",
       "      <th>choc</th>\n",
       "      <th>manv</th>\n",
       "      <th>motor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200500000001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200500000001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200500000001</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200500000001</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200500000001</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200500000001</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200500000002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200500000002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200500000003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>200500000003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Num_Acc  place  catu  grav  sexe  trajet  secu1  locp actp  etatp  \\\n",
       "0  200500000001      1     1     4     1       1      1     0    0      0   \n",
       "1  200500000001      1     1     3     2       3      1     0    0      0   \n",
       "2  200500000001      2     2     1     1       0      1     0    0      0   \n",
       "3  200500000001      4     2     1     1       0      3     0    0      0   \n",
       "4  200500000001      5     2     1     1       0      1     0    0      0   \n",
       "5  200500000001      3     2     1     2       0      1     0    0      0   \n",
       "6  200500000002      1     1     1     1       5      1     0    0      0   \n",
       "7  200500000002      1     1     3     1       5      2     0    0      0   \n",
       "8  200500000003      1     1     1     1       1      2     0    0      0   \n",
       "9  200500000003      1     1     3     1       1      2     0    0      0   \n",
       "\n",
       "   ...  infra situ  senc  catv  occutc obs  obsm  choc  manv  motor  \n",
       "0  ...      0    1     0     7     0.0   0     2     1     1     -1  \n",
       "1  ...      0    1     0     7     0.0   0     2     8    10     -1  \n",
       "2  ...      0    1     0     7     0.0   0     2     8    10     -1  \n",
       "3  ...      0    1     0     7     0.0   0     2     8    10     -1  \n",
       "4  ...      0    1     0     7     0.0   0     2     8    10     -1  \n",
       "5  ...      0    1     0     7     0.0   0     2     8    10     -1  \n",
       "6  ...      0    5     0     7     0.0   0     2     7    16     -1  \n",
       "7  ...      0    5     0     2     0.0   0     2     1     1     -1  \n",
       "8  ...      0    5     0     2     0.0   0     2     1     1     -1  \n",
       "9  ...      0    5     0     2     0.0   0     2     1     1     -1  \n",
       "\n",
       "[10 rows x 50 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the head of the result\n",
    "concat_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa284bee-4c6d-42de-b783-4dfcf1c3d5d4",
   "metadata": {},
   "source": [
    "***\n",
    "# Save the generated dataset to a new file :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c3197c-c9f0-4068-9c91-fec72e31c73c",
   "metadata": {},
   "source": [
    "- The generated dataset is saved to *'data/merged_data_2005_2020.csv'*  in the ***data/*** folder :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "74ff65fe-ad1b-436a-b517-4bdde67b6f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_data.to_csv(path_or_buf= 'data/merged_data_2005_2020.csv',sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
